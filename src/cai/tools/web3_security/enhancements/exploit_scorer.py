"""
Exploit Viability Scoring Tool

This module implements game-theoretic scoring for exploit viability,
helping prioritize findings by actual exploitation potential.

Key formula: Exploit_Score = (Severity × Likelihood × Payoff) / (Effort × Detection_Risk)

Enhanced with:
- Validation level multipliers (static_only vs fork_poc)
- Negative signal penalties (initialized, privileged, paused, mitigated)
- Attacker model constraints (EOA vs MEV vs governance)
"""

import json
import re
import math
from typing import Any, Dict, List, Optional
from cai.sdk.agents import function_tool


# =============================================================================
# Validation Level Multipliers
# =============================================================================
# These adjust scores based on how well the finding has been validated.
# Prevents "paper alpha" - theoretical findings ranking too high.
VALIDATION_LEVELS = {
    "static_only": 0.30,       # Tool finding only, no reproduction
    "manual_review": 0.45,     # Human reviewed code, identified issue
    "poc_local": 0.60,         # Reproduced in local Foundry/Hardhat tests
    "fork_poc": 0.90,          # Reproduced on mainnet fork at pinned block
    "fork_adversarial": 1.00,  # Reproduced under varied block/liquidity/MEV
}

# =============================================================================
# Attacker Model Constraints
# =============================================================================
# Different attacker types have different capabilities and costs.
ATTACKER_MODELS = {
    "EOA": {
        "description": "Externally owned account, basic attacker",
        "can_mev": False,
        "can_governance": False,
        "cost_multiplier": 1.0,
    },
    "MEV_SEARCHER": {
        "description": "MEV bot operator with bundling capability",
        "can_mev": True,
        "can_governance": False,
        "cost_multiplier": 0.7,  # Lower effective cost due to MEV extraction
    },
    "GOVERNANCE_ATTACKER": {
        "description": "Entity with significant token holdings",
        "can_mev": False,
        "can_governance": True,
        "cost_multiplier": 1.5,  # Higher cost (needs tokens)
    },
    "SOPHISTICATED": {
        "description": "Well-funded attacker with all capabilities",
        "can_mev": True,
        "can_governance": True,
        "cost_multiplier": 0.5,
    },
}

# =============================================================================
# Severity Mappings
# =============================================================================
SEVERITY_SCORES = {
    "critical": 10,
    "high": 8,
    "medium": 5,
    "low": 3,
    "informational": 1,
    "info": 1,
}

# Vulnerability type effort estimates (1-10, higher = more effort)
VULN_EFFORT_ESTIMATES = {
    # Easy to exploit (low effort)
    "unprotected-upgrade": 2,
    "suicidal": 2,
    "arbitrary-send": 3,
    "uninitialized-state": 3,
    "default-visibility": 3,
    
    # Medium effort
    "reentrancy-eth": 4,
    "reentrancy-no-eth": 5,
    "unchecked-transfer": 5,
    "tx-origin": 4,
    "delegatecall-loop": 5,
    
    # Higher effort
    "oracle-manipulation": 6,
    "flash-loan-attack": 7,
    "price-manipulation": 7,
    "integer-overflow": 6,
    
    # Complex (high effort)
    "cross-contract-reentrancy": 8,
    "governance-attack": 8,
    "economic-attack": 9,
    
    # Default
    "default": 5,
}

# Detection risk by vulnerability type (1-10, higher = easier to detect/front-run)
DETECTION_RISK = {
    "reentrancy-eth": 7,  # Well-known, often monitored
    "flash-loan-attack": 8,  # Easy to detect on-chain
    "oracle-manipulation": 6,
    "price-manipulation": 7,
    "integer-overflow": 4,  # Harder to detect pre-execution
    "unprotected-upgrade": 3,  # Often unnoticed until exploited
    "arbitrary-send": 5,
    "default": 5,
}


def _get_severity_score(severity: str) -> int:
    """Convert severity string to numeric score."""
    if isinstance(severity, (int, float)):
        return min(max(int(severity), 1), 10)
    return SEVERITY_SCORES.get(severity.lower(), 5)


def _get_effort_estimate(vuln_type: str) -> int:
    """Get effort estimate for vulnerability type."""
    normalized = vuln_type.lower().replace("_", "-").replace(" ", "-")
    
    for key, value in VULN_EFFORT_ESTIMATES.items():
        if key in normalized or normalized in key:
            return value
    
    return VULN_EFFORT_ESTIMATES["default"]


def _get_detection_risk(vuln_type: str) -> int:
    """Get detection risk for vulnerability type."""
    normalized = vuln_type.lower().replace("_", "-").replace(" ", "-")
    
    for key, value in DETECTION_RISK.items():
        if key in normalized or normalized in key:
            return value
    
    return DETECTION_RISK["default"]


@function_tool
def score_exploit_viability(finding: str, context: str = "{}", ctf=None) -> str:
    """
    Calculate game-theoretic viability score for a single finding.
    
    Uses the formula: Exploit_Score = (Severity × Likelihood × Payoff) / (Effort × Detection_Risk)
    
    Enhanced with validation levels, negative signals, and attacker model constraints.
    
    Args:
        finding: JSON string of a vulnerability finding with fields:
                 type, severity, confidence, description, location
        context: Optional JSON context with additional info:
                 - tvl: Total value locked (USD). If not provided, uses conservative default.
                 - validation: Validation level (static_only, manual_review, poc_local, fork_poc, fork_adversarial)
                 - attacker_model: Attacker type (EOA, MEV_SEARCHER, GOVERNANCE_ATTACKER, SOPHISTICATED)
                 - already_initialized: bool - if init vuln but contract is already initialized
                 - requires_privileged_role: bool - if exploit requires admin/owner
                 - paused: bool - if contract is currently paused
                 - exploit_requires_mev: bool - if exploit needs MEV capabilities
                 - mitigated: bool - if there's a known mitigation in place
    
    Returns:
        JSON string with viability score and detailed breakdown.
    
    Example:
        score_exploit_viability(
            '{"type": "reentrancy-eth", "severity": "High", "confidence": "High"}',
            '{"tvl": 5000000, "validation": "fork_poc"}'
        )
    """
    try:
        if isinstance(finding, str):
            finding_data = json.loads(finding)
        else:
            finding_data = finding
        
        if isinstance(context, str):
            context_data = json.loads(context)
        else:
            context_data = context
        
        # Extract finding attributes
        vuln_type = finding_data.get("type", finding_data.get("check", "unknown"))
        severity = finding_data.get("severity", "medium")
        confidence = finding_data.get("confidence", "medium")
        
        # Calculate component scores
        severity_score = _get_severity_score(severity)
        effort_score = _get_effort_estimate(vuln_type)
        detection_risk = _get_detection_risk(vuln_type)
        
        # Confidence affects likelihood
        confidence_map = {"high": 0.9, "medium": 0.6, "low": 0.3}
        if isinstance(confidence, str):
            likelihood = confidence_map.get(confidence.lower(), 0.5)
        else:
            likelihood = min(max(float(confidence), 0), 1)
        
        # =================================================================
        # TVL Handling - fail closed on unknown (conservative default)
        # =================================================================
        tvl = context_data.get("tvl", None)
        if tvl is None:
            # Unknown TVL => treat payoff as low until proven; avoids "paper alpha"
            tvl = 50000  # Conservative $50k default
            tvl_assumption_quality = "unknown_default_low"
        else:
            tvl_assumption_quality = "provided"
        
        # Payoff estimation (percentage of TVL that could be extracted)
        payoff_percentage = {
            10: 0.5,   # Critical - could drain 50%
            8: 0.2,    # High - 20%
            5: 0.05,   # Medium - 5%
            3: 0.01,   # Low - 1%
        }
        estimated_payoff = tvl * payoff_percentage.get(severity_score, 0.05) * likelihood
        
        # Normalize payoff for scoring (log scale to handle large values)
        payoff_factor = math.log10(max(estimated_payoff, 1)) / 6  # Normalize to ~0-1 range
        
        # =================================================================
        # Validation Level Multiplier (stops static-only inflation)
        # =================================================================
        validation = context_data.get("validation", "static_only")
        validation_level = VALIDATION_LEVELS.get(str(validation).lower(), 0.30)
        
        # =================================================================
        # Negative Signal Penalties (stops AI optimism)
        # =================================================================
        penalty = 1.0
        triggered_penalties = []
        
        # Init-only vulnerability but contract is already initialized
        if context_data.get("already_initialized") is True and "init" in vuln_type.lower():
            penalty *= 0.05
            triggered_penalties.append("already_initialized (0.05x)")
        
        # Exploit requires privileged role (owner, admin, etc.)
        if context_data.get("requires_privileged_role") is True:
            penalty *= 0.25
            triggered_penalties.append("requires_privileged_role (0.25x)")
        
        # Contract is currently paused
        if context_data.get("paused") is True:
            penalty *= 0.30
            triggered_penalties.append("paused (0.30x)")
        
        # Exploit requires MEV capabilities
        if context_data.get("exploit_requires_mev") is True:
            penalty *= 0.70
            triggered_penalties.append("exploit_requires_mev (0.70x)")
        
        # Known mitigation exists
        if context_data.get("mitigated") is True:
            penalty *= 0.20
            triggered_penalties.append("mitigated (0.20x)")
        
        # =================================================================
        # Attacker Model Constraints
        # =================================================================
        attacker = str(context_data.get("attacker_model", "EOA")).upper()
        attacker_info = ATTACKER_MODELS.get(attacker, ATTACKER_MODELS["EOA"])
        
        # EOA can't do governance attacks efficiently
        if attacker == "EOA" and "governance" in vuln_type.lower():
            penalty *= 0.30
            triggered_penalties.append("EOA_cant_governance (0.30x)")
        
        # Non-MEV attacker can't do sandwich/MEV attacks efficiently
        if not attacker_info["can_mev"] and any(x in vuln_type.lower() for x in ["sandwich", "frontrun", "backrun", "mev"]):
            penalty *= 0.40
            triggered_penalties.append("non_mev_attacker (0.40x)")
        
        # =================================================================
        # Calculate Final Score
        # =================================================================
        numerator = severity_score * likelihood * payoff_factor
        denominator = (effort_score / 10) * (detection_risk / 10)
        
        if denominator > 0:
            base_score = (numerator / denominator) * 10  # Scale to 0-10
        else:
            base_score = numerator * 10
        
        # Apply validation level and penalties
        exploit_score = base_score * validation_level * penalty
        exploit_score = min(exploit_score, 10)  # Cap at 10
        
        # =================================================================
        # Determine Priority (based on adjusted score)
        # =================================================================
        if exploit_score >= 8:
            priority = "CRITICAL"
            action = "Immediate investigation and PoC development required"
        elif exploit_score >= 6:
            priority = "HIGH"
            action = "Prioritize for deep analysis and validation"
        elif exploit_score >= 4:
            priority = "MEDIUM"
            action = "Include in comprehensive review"
        elif exploit_score >= 2:
            priority = "LOW"
            action = "Document for completeness"
        else:
            priority = "INFORMATIONAL"
            action = "Note for awareness only"
        
        # Add upgrade recommendation if validation is low
        if validation_level < 0.5 and base_score >= 6:
            action += " - RECOMMEND: Validate with fork PoC to increase confidence"
        
        return json.dumps({
            "exploit_score": round(exploit_score, 2),
            "base_score_before_adjustments": round(base_score, 2),
            "priority": priority,
            "recommended_action": action,
            "breakdown": {
                "severity_score": severity_score,
                "likelihood": round(likelihood, 2),
                "effort_score": effort_score,
                "detection_risk": detection_risk,
                "payoff_factor": round(payoff_factor, 3),
            },
            "adjustments": {
                "validation_level": validation_level,
                "validation_type": str(validation),
                "penalty_multiplier": round(penalty, 4),
                "triggered_penalties": triggered_penalties,
                "attacker_model": attacker,
            },
            "economics": {
                "estimated_payoff_usd": round(estimated_payoff, 2),
                "tvl_assumption": tvl,
                "tvl_assumption_quality": tvl_assumption_quality,
            },
            "finding_summary": {
                "type": vuln_type,
                "severity": severity,
                "confidence": confidence,
            },
        }, indent=2)
    
    except Exception as e:
        return json.dumps({
            "error": f"Failed to score exploit viability: {str(e)}",
            "exploit_score": 0,
        })


@function_tool
def rank_findings_by_exploitability(findings: str, context: str = "{}", ctf=None) -> str:
    """
    Rank multiple findings by their exploitability score.
    
    Processes all findings and returns them sorted by exploit viability,
    enabling strategic prioritization of security research.
    
    Args:
        findings: JSON string of vulnerability findings array.
        context: Optional JSON context for economic analysis.
    
    Returns:
        JSON string with ranked findings and summary statistics.
    
    Example:
        rank_findings_by_exploitability('[{"type": "reentrancy-eth", ...}, {"type": "low-level-calls", ...}]')
    """
    try:
        if isinstance(findings, str):
            findings_list = json.loads(findings)
        else:
            findings_list = findings
        
        if not isinstance(findings_list, list):
            findings_list = [findings_list]
        
        if isinstance(context, str):
            context_data = json.loads(context)
        else:
            context_data = context
        
        # Score each finding
        scored_findings = []
        for finding in findings_list:
            score_result = json.loads(score_exploit_viability(json.dumps(finding), json.dumps(context_data)))
            
            if "error" not in score_result:
                scored_findings.append({
                    "original_finding": finding,
                    "exploit_score": score_result["exploit_score"],
                    "priority": score_result["priority"],
                    "breakdown": score_result["breakdown"],
                    "recommended_action": score_result["recommended_action"],
                })
        
        # Sort by exploit score (descending)
        scored_findings.sort(key=lambda x: x["exploit_score"], reverse=True)
        
        # Add rank
        for i, f in enumerate(scored_findings):
            f["rank"] = i + 1
        
        # Calculate statistics
        scores = [f["exploit_score"] for f in scored_findings]
        
        priority_counts = {
            "CRITICAL": len([f for f in scored_findings if f["priority"] == "CRITICAL"]),
            "HIGH": len([f for f in scored_findings if f["priority"] == "HIGH"]),
            "MEDIUM": len([f for f in scored_findings if f["priority"] == "MEDIUM"]),
            "LOW": len([f for f in scored_findings if f["priority"] == "LOW"]),
            "INFORMATIONAL": len([f for f in scored_findings if f["priority"] == "INFORMATIONAL"]),
        }
        
        return json.dumps({
            "ranked_findings": scored_findings,
            "statistics": {
                "total_findings": len(scored_findings),
                "average_score": round(sum(scores) / len(scores), 2) if scores else 0,
                "max_score": max(scores) if scores else 0,
                "min_score": min(scores) if scores else 0,
                "priority_distribution": priority_counts,
            },
            "top_3_recommendations": [
                {
                    "rank": f["rank"],
                    "type": f["original_finding"].get("type", f["original_finding"].get("check", "unknown")),
                    "score": f["exploit_score"],
                    "action": f["recommended_action"],
                }
                for f in scored_findings[:3]
            ],
            "strategic_digest": _generate_strategic_summary(scored_findings),
        }, indent=2)
    
    except Exception as e:
        return json.dumps({
            "error": f"Failed to rank findings: {str(e)}",
            "ranked_findings": [],
        })


def _generate_strategic_summary(scored_findings: List[Dict]) -> str:
    """Generate a strategic summary for the agent."""
    critical = [f for f in scored_findings if f["priority"] == "CRITICAL"]
    high = [f for f in scored_findings if f["priority"] == "HIGH"]
    
    summary_parts = []
    
    if critical:
        summary_parts.append(f"IMMEDIATE: {len(critical)} critical finding(s) require immediate investigation - "
                          f"focus on {critical[0]['original_finding'].get('type', 'unknown')} first.")
    
    if high:
        types = list(set(f["original_finding"].get("type", "unknown") for f in high))
        summary_parts.append(f"HIGH PRIORITY: {len(high)} high-priority finding(s) in categories: {', '.join(types[:3])}")
    
    if not critical and not high:
        summary_parts.append("No critical or high-priority exploitable findings detected. "
                          "Consider deeper analysis or alternative attack vectors.")
    
    return " | ".join(summary_parts)


@function_tool
def estimate_attacker_cost(exploit_path: str, gas_price_gwei: float = 30.0, eth_price_usd: float = 2000.0, ctf=None) -> str:
    """
    Estimate the cost for an attacker to execute an exploit.
    
    Considers gas costs, flash loan fees, DEX fees, and other
    economic factors that affect exploit profitability.
    
    Args:
        exploit_path: JSON string describing the exploit steps or path.
        gas_price_gwei: Current gas price in Gwei.
        eth_price_usd: Current ETH price in USD.
    
    Returns:
        JSON string with detailed cost breakdown.
    
    Example:
        estimate_attacker_cost('{"steps": ["flash_loan", "swap", "exploit", "repay"]}', gas_price_gwei=50)
    """
    try:
        if isinstance(exploit_path, str):
            path_data = json.loads(exploit_path)
        else:
            path_data = exploit_path
        
        # Default step costs (in gas units)
        step_gas_costs = {
            "flash_loan": 300000,
            "swap": 150000,
            "transfer": 65000,
            "approve": 46000,
            "exploit": 200000,  # Variable, this is estimate
            "repay": 100000,
            "liquidate": 400000,
            "governance_vote": 100000,
            "default": 100000,
        }
        
        # Flash loan fees (as percentage of borrowed amount)
        flash_loan_fees = {
            "aave": 0.0009,  # 0.09%
            "dydx": 0.0,     # Free
            "uniswap": 0.003,  # 0.3%
            "default": 0.001,
        }
        
        # Calculate gas costs
        steps = path_data.get("steps", path_data.get("path", ["exploit"]))
        total_gas = 0
        
        for step in steps:
            step_lower = step.lower() if isinstance(step, str) else "default"
            for key, gas in step_gas_costs.items():
                if key in step_lower:
                    total_gas += gas
                    break
            else:
                total_gas += step_gas_costs["default"]
        
        # Calculate costs in ETH and USD
        gas_cost_eth = (total_gas * gas_price_gwei) / 1e9
        gas_cost_usd = gas_cost_eth * eth_price_usd
        
        # Estimate flash loan fee if applicable
        flash_loan_amount = path_data.get("flash_loan_amount", 0)
        flash_loan_provider = path_data.get("flash_loan_provider", "default")
        flash_loan_fee_rate = flash_loan_fees.get(flash_loan_provider, flash_loan_fees["default"])
        flash_loan_fee = flash_loan_amount * flash_loan_fee_rate
        
        # Total cost
        total_cost_usd = gas_cost_usd + flash_loan_fee
        
        # Minimum profitable exploit
        # Assuming 2x return requirement for risk
        min_profitable_exploit = total_cost_usd * 2
        
        return json.dumps({
            "cost_breakdown": {
                "gas_units": total_gas,
                "gas_cost_eth": round(gas_cost_eth, 6),
                "gas_cost_usd": round(gas_cost_usd, 2),
                "flash_loan_fee_usd": round(flash_loan_fee, 2),
                "total_cost_usd": round(total_cost_usd, 2),
            },
            "parameters": {
                "gas_price_gwei": gas_price_gwei,
                "eth_price_usd": eth_price_usd,
                "steps_count": len(steps),
            },
            "profitability_analysis": {
                "minimum_profitable_exploit_usd": round(min_profitable_exploit, 2),
                "break_even_usd": round(total_cost_usd, 2),
            },
            "recommendations": {
                "gas_optimization": total_gas > 500000,
                "consider_l2": gas_cost_usd > 100,
                "flash_loan_provider": "dydx" if flash_loan_amount > 0 else "n/a",
            },
        }, indent=2)
    
    except Exception as e:
        return json.dumps({
            "error": f"Failed to estimate attacker cost: {str(e)}",
            "cost_breakdown": {},
        })
